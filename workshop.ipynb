{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "starter_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Machine Translation for Translators Workshop\n",
        "Localization summer school '21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "### Note before beginning:\n",
        "\n",
        "#### - This coding template is based on Masakhane's starter notebook (https://github.com/masakhane-io/masakhane-mt)\n",
        "#### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "#### - The TL;DR: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "#### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "#### - With 100 epochs, it should take around 7 hours to run in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "In this workshop we will use open corpus available from OPUS repository to train a translation model. We will first download the data, create training, development, testing sets from it and then use JoeyNMT to train a baseline model. \n",
        "\n",
        "In the next cell, you need to set the languages you want to work with and specify which corpus you want to use to train. \n",
        "\n",
        "To select a corpus go to https://opus.nlpl.eu/, enter your language pair and select one that you think is more appropriate (size, domain)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cn3tgQLzUxwn"
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"tr\"\n",
        "opus_corpus = \"TED2020\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"corpus\"] = opus_corpus\n",
        "os.environ[\"tag\"] = tag"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO5IY_RywQyA",
        "outputId": "8cecb718-3ee6-4af1-ed32-ec6444b2b70c"
      },
      "source": [
        "# This will save it to a folder in our gdrive instead!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p \"/content/drive/My Drive/mt-workshop/$src-$tgt-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/mt-workshop/%s-%s-%s\" % (source_language, target_language, tag)\n",
        "\n",
        "!echo $gdrive_path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/mt-workshop/en-tr-baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gA75Fs9ys8Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db166efa-319b-460a-f41b-add94bf2a05b"
      },
      "source": [
        "# Install opus-tools (Warning! This is not really python)\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "  Downloading opustools_pkg-0.0.52-py3-none-any.whl (80 kB)\n",
            "\u001b[?25l\r\u001b[K     |████                            | 10 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 20 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 80 kB 3.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xq-tDZVks7ZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e426bab6-64fb-4afe-a98a-669af3a95b82"
      },
      "source": [
        "# Downloading our corpus \n",
        "! opus_read -d $corpus -s $src -t $tgt -wm moses -w $corpus.$src $corpus.$tgt -q\n",
        "\n",
        "# Extract the corpus file\n",
        "! gunzip ${corpus}_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/TED2020/latest/xml/en-tr.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   2 MB https://object.pouta.csc.fi/OPUS-TED2020/v1/xml/en-tr.xml.gz\n",
            "  47 MB https://object.pouta.csc.fi/OPUS-TED2020/v1/xml/en.zip\n",
            "  37 MB https://object.pouta.csc.fi/OPUS-TED2020/v1/xml/tr.zip\n",
            "\n",
            "  86 MB Total size\n",
            "./TED2020_latest_xml_en-tr.xml.gz ... 100% of 2 MB\n",
            "./TED2020_latest_xml_en.zip ... 100% of 47 MB\n",
            "./TED2020_latest_xml_tr.zip ... 100% of 37 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sazl7hv9xZFg"
      },
      "source": [
        "# Read the corpus into python lists\n",
        "source_file = opus_corpus + '.' + source_language\n",
        "target_file = opus_corpus + '.' + target_language\n",
        "\n",
        "src_all = [sentence.strip() for sentence in open(source_file).readlines()]\n",
        "tgt_all = [sentence.strip() for sentence in open(target_file).readlines()]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjcOBlYMxxTC",
        "outputId": "0557e0e3-8f90-4e9f-87b4-8f0f1f3c5733"
      },
      "source": [
        "# Let's take a peek at the files\n",
        "print(\"Source size:\", len(src_all))\n",
        "print(\"Target size:\", len(tgt_all))\n",
        "print(\"--------\")\n",
        "\n",
        "peek_size = 5\n",
        "for i in range(peek_size):\n",
        "  print(\"Sent #\", i)\n",
        "  print(\"SRC:\", src_all[i])\n",
        "  print(\"TGT:\", tgt_all[i])\n",
        "  print(\"---------\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source size: 374378\n",
            "Target size: 374378\n",
            "--------\n",
            "Sent # 0\n",
            "SRC: Thank you so much , Chris .\n",
            "TGT: Çok teşekkür ederim Chris .\n",
            "---------\n",
            "Sent # 1\n",
            "SRC: And it 's truly a great honor to have the opportunity to come to this stage twice ; I 'm extremely grateful .\n",
            "TGT: Bu sahnede ikinci kez yer alma fırsatına sahip olmak gerçekten büyük bir onur . Çok minnettarım .\n",
            "---------\n",
            "Sent # 2\n",
            "SRC: I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
            "TGT: Bu konferansta çok mutlu oldum , ve anlattıklarımla ilgili güzel yorumlarınız için sizlere çok teşekkür ederim .\n",
            "---------\n",
            "Sent # 3\n",
            "SRC: And I say that sincerely , partly because ( Mock sob ) I need that .\n",
            "TGT: Bunu içtenlikle söylüyorum , çünkü ... ( Ağlama taklidi ) Buna ihtiyacım var .\n",
            "---------\n",
            "Sent # 4\n",
            "SRC: ( Laughter ) Put yourselves in my position .\n",
            "TGT: ( Kahkahalar ) Kendinizi benim yerime koyun !\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Making training, development and testing sets\n",
        "\n",
        "We need to pick training, development and testing sets from our corpus. Training set will contain the sentences that we'll teach our model. Development set will be used to see how our model is progressing during the training. And finally, testing set will be used to evaluate the model.\n",
        "\n",
        "You can optionally load your own testing set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkcE9T75y9za",
        "outputId": "1d538b86-bb9a-4687-f140-7e2ca7225b7c"
      },
      "source": [
        "# TODO: Determine ratios of each set\n",
        "all_size = len(src_all)\n",
        "dev_size = 1000\n",
        "test_size = 1000\n",
        "train_size = all_size - test_size - dev_size\n",
        "\n",
        "src_train = src_all[0:train_size]\n",
        "tgt_train = tgt_all[0:train_size]\n",
        "\n",
        "src_dev = src_all[train_size:train_size+dev_size]\n",
        "tgt_dev = tgt_all[train_size:train_size+dev_size]\n",
        "\n",
        "src_test = src_all[train_size+dev_size:all_size]\n",
        "tgt_test = tgt_all[train_size+dev_size:all_size]\n",
        "\n",
        "print(\"Set sizes\")\n",
        "print(\"All:\", all_size)\n",
        "print(\"Train:\", train_size)\n",
        "print(\"Dev:\", dev_size)\n",
        "print(\"Test:\", test_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Set sizes\n",
            "All: 374378\n",
            "Train: 372378\n",
            "Dev: 1000\n",
            "Test: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for neural machine translation is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- BPE tokenization limits the number of vocabulary into a certain size by smartly dividing words into subwords\n",
        "\n",
        "- This is especially useful for agglutinative languages (like Turkish) where vocabulary is effectively endless. \n",
        "\n",
        "- Below you have the scripts for doing BPE tokenization of our data. We use bpemb library that has pre-trained BPE models to convert our data into subwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xYKgReL6A76",
        "outputId": "f943f5c1-419c-4e01-e0af-ce0cf3bf4187"
      },
      "source": [
        "! pip install bpemb\n",
        "from bpemb import BPEmb\n",
        "\n",
        "BPE_VOCAB_SIZE = 5000\n",
        "bpemb_src = BPEmb(lang=source_language, vs=BPE_VOCAB_SIZE, segmentation_only=True, preprocess=False)\n",
        "bpemb_tgt = BPEmb(lang=target_language, vs=BPE_VOCAB_SIZE, segmentation_only=True, preprocess=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb) (1.20.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bpemb) (4.41.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bpemb) (5.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb) (2.10)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.3 sentencepiece-0.1.96\n",
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs5000.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 315918/315918 [00:00<00:00, 759438.49B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/tr/tr.wiki.bpe.vs5000.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 315775/315775 [00:00<00:00, 696649.63B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_RWTDq169WQ",
        "outputId": "e2c68f65-1b1a-4b3b-de0a-e8383b822473"
      },
      "source": [
        "# Testing BPE encoding\n",
        "encoded_tokens = bpemb_src.encode(\"This is a test sentence to demonstrate how BPE encoding works for our source language.\")\n",
        "print(encoded_tokens)\n",
        "\n",
        "encoded_string = \" \".join(encoded_tokens)\n",
        "print(encoded_string)\n",
        "\n",
        "decoded_string = bpemb_src.decode(encoded_tokens)\n",
        "print(decoded_string)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁', 'T', 'h', 'is', '▁is', '▁a', '▁test', '▁sent', 'ence', '▁to', '▁demonstr', 'ate', '▁how', '▁', 'BPE', '▁enc', 'od', 'ing', '▁works', '▁for', '▁our', '▁source', '▁language', '.']\n",
            "▁ T h is ▁is ▁a ▁test ▁sent ence ▁to ▁demonstr ate ▁how ▁ BPE ▁enc od ing ▁works ▁for ▁our ▁source ▁language .\n",
            "This is a test sentence to demonstrate how BPE encoding works for our source language.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMMbGLEX8pct"
      },
      "source": [
        "# Shortcut functions to encode and decode\n",
        "def encode_bpe(string, lang, to_lower=True):\n",
        "  if to_lower:\n",
        "    string = string.lower()\n",
        "  if lang == source_language:\n",
        "    return \" \".join(bpemb_src.encode(string))\n",
        "  elif lang == target_language:\n",
        "    return \" \".join(bpemb_tgt.encode(string))\n",
        "  else:\n",
        "    return \"\"\n",
        "\n",
        "def decode_bpe(string, lang):\n",
        "  tokens = string.strip().split()\n",
        "  if lang == source_language:\n",
        "    return bpemb_src.decode(tokens)\n",
        "  elif lang == target_language:\n",
        "    return bpemb_tgt.decode(tokens)\n",
        "  else:\n",
        "    return \"\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fMMGYQ27ZUN"
      },
      "source": [
        "# Let's encode all our sets with BPE\n",
        "src_train_bpe = [encode_bpe(sentence, source_language) for sentence in src_train]\n",
        "tgt_train_bpe = [encode_bpe(sentence, target_language) for sentence in tgt_train]\n",
        "\n",
        "src_dev_bpe = [encode_bpe(sentence, source_language) for sentence in src_dev]\n",
        "tgt_dev_bpe = [encode_bpe(sentence, target_language) for sentence in tgt_dev]\n",
        "\n",
        "src_test_bpe = [encode_bpe(sentence, source_language) for sentence in src_test]\n",
        "tgt_test_bpe = [encode_bpe(sentence, target_language) for sentence in tgt_test]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRQ7hNIS0D0z"
      },
      "source": [
        "# Now let's write all our sets into separate files\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_train, tgt_train):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")\n",
        "\n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_dev, tgt_dev):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")\n",
        "\n",
        "with open(\"test.\"+source_language, \"w\") as src_file, open(\"test.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_test, tgt_test):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")\n",
        "\n",
        "with open(\"train.bpe.\"+source_language, \"w\") as src_file, open(\"train.bpe.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_train_bpe, tgt_train_bpe):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")\n",
        "\n",
        "with open(\"dev.bpe.\"+source_language, \"w\") as src_file, open(\"dev.bpe.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_dev_bpe, tgt_dev_bpe):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")\n",
        "\n",
        "with open(\"test.bpe.\"+source_language, \"w\") as src_file, open(\"test.bpe.\"+target_language, \"w\") as tgt_file:\n",
        "  for s, t in zip(src_test_bpe, tgt_test_bpe):\n",
        "    src_file.write(s+\"\\n\")\n",
        "    tgt_file.write(t+\"\\n\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hxxBOCA-xXhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0ead9a-d05c-409c-c12e-70b3972f377a"
      },
      "source": [
        "# Doublecheck the files. There should be no extra quotation marks or weird characters.\n",
        "! head -n5 train.*\n",
        "! head -n5 dev.*\n",
        "! head -n5 test.*"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.bpe.en <==\n",
            "▁ T h ank ▁you ▁so ▁much ▁, ▁ C h ris ▁.\n",
            "▁ A nd ▁it ▁' s ▁tr u ly ▁a ▁great ▁honor ▁to ▁have ▁the ▁opportun ity ▁to ▁come ▁to ▁this ▁stage ▁twice ▁; ▁ I ▁' m ▁extrem ely ▁gr ate ful ▁.\n",
            "▁ I ▁have ▁been ▁bl own ▁away ▁by ▁this ▁conference ▁, ▁and ▁ I ▁want ▁to ▁than k ▁all ▁of ▁you ▁for ▁the ▁many ▁n ice ▁com ments ▁about ▁what ▁ I ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
            "▁ A nd ▁ I ▁say ▁that ▁s inc er ely ▁, ▁part ly ▁because ▁( ▁ M ock ▁so b ▁ ) ▁ I ▁need ▁that ▁.\n",
            "▁( ▁ L augh ter ▁ ) ▁ P ut ▁y ours elves ▁in ▁my ▁position ▁.\n",
            "\n",
            "==> train.bpe.tr <==\n",
            "▁ Ç ok ▁teş ek kür ▁eder im ▁ C h ris ▁.\n",
            "▁ B u ▁sahne de ▁ikinci ▁kez ▁yer ▁al ma ▁fır sat ına ▁sahip ▁olmak ▁ger ç ekten ▁büyük ▁bir ▁onur ▁. ▁ Ç ok ▁min net tar ım ▁.\n",
            "▁ B u ▁konfer ans ta ▁çok ▁mut lu ▁ol d um ▁, ▁ve ▁anlat t ıkları m la ▁ilgili ▁güzel ▁yorum ların ız ▁için ▁s iz lere ▁çok ▁teş ek kür ▁eder im ▁.\n",
            "▁ B unu ▁iç ten likle ▁söy l üyor um ▁, ▁çünkü ▁... ▁( ▁ A ğ lama ▁tak li di ▁) ▁ B una ▁ihtiy ac ım ▁var ▁.\n",
            "▁( ▁ K ah k ah alar ▁) ▁ K end in izi ▁benim ▁yer ime ▁koy un ▁ !\n",
            "\n",
            "==> train.en <==\n",
            "Thank you so much , Chris .\n",
            "And it 's truly a great honor to have the opportunity to come to this stage twice ; I 'm extremely grateful .\n",
            "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
            "And I say that sincerely , partly because ( Mock sob ) I need that .\n",
            "( Laughter ) Put yourselves in my position .\n",
            "\n",
            "==> train.tr <==\n",
            "Çok teşekkür ederim Chris .\n",
            "Bu sahnede ikinci kez yer alma fırsatına sahip olmak gerçekten büyük bir onur . Çok minnettarım .\n",
            "Bu konferansta çok mutlu oldum , ve anlattıklarımla ilgili güzel yorumlarınız için sizlere çok teşekkür ederim .\n",
            "Bunu içtenlikle söylüyorum , çünkü ... ( Ağlama taklidi ) Buna ihtiyacım var .\n",
            "( Kahkahalar ) Kendinizi benim yerime koyun !\n",
            "==> dev.bpe.en <==\n",
            "▁ T he y ▁decided ▁to ▁take ▁a ▁block - by - bl ock - by - bl ock ▁str ate gy ▁.\n",
            "▁ S o ▁within ▁the ▁neighbor hood ▁of ▁ B right m oor ▁, ▁you ▁' ll ▁find ▁a ▁ 2 1 - bl ock ▁mic r one igh bor hood ▁called ▁ B right m oor ▁ F arm way ▁.\n",
            "▁ N ow ▁, ▁what ▁was ▁a ▁not or ious ▁, ▁uns af e ▁, ▁und ers erved ▁community ▁has ▁transform ed ▁into ▁a ▁wel com ing ▁, ▁beaut if ul ▁, ▁sa fe ▁farm way ▁, ▁l ush ▁with ▁par ks ▁and ▁gard ens ▁and ▁far ms ▁and ▁green h ous es ▁.\n",
            "▁ T h is ▁t ight - kn it ▁community ▁also ▁came ▁together ▁recently ▁, ▁and ▁they ▁purchased ▁an ▁aband oned ▁building ▁, ▁an ▁aband oned ▁building ▁that ▁was ▁in ▁dis rep air ▁and ▁in ▁fore cl os ure ▁.\n",
            "▁ A nd ▁with ▁the ▁help ▁of ▁friends ▁and ▁families ▁and ▁vol un te ers ▁, ▁they ▁were ▁able ▁to ▁take ▁down ▁the ▁bul let pro of ▁glass ▁, ▁they ▁were ▁able ▁to ▁cle an ▁up ▁the ▁ground s ▁and ▁they ▁transform ed ▁that ▁building ▁into ▁a ▁community ▁kit chen ▁, ▁into ▁a ▁c af e ▁, ▁into ▁a ▁store f ront ▁.\n",
            "\n",
            "==> dev.bpe.tr <==\n",
            "▁ O n lar ▁bl ok - b l ok ▁iş leme ▁str ate j isinde ▁karar ▁k ıldı lar ▁.\n",
            "▁ D ol ay ısıyla ▁ B right mo or ▁ M ah all esi ▁' nde ▁ 2 1 ▁bl ok tan ▁oluşan ▁ B right mo or ▁ F ar m way ▁adında ▁mik ro ▁mahall eler ▁gör ür s ün üz ▁.\n",
            "▁ Ş im diler de ▁, ▁kötü ▁ş ö h ret li ▁, ▁güvenlik siz ▁, ▁yet ersiz ▁hizmet ▁almış ▁bu ▁topluluk ▁dav et kar ▁, ▁güzel ▁ve ▁güven li ▁bir ▁tar la ▁yol una ▁, ▁yem y eşil ▁park ları ▁, ▁bahç eleri ▁, ▁tar l aları ▁ve ▁ser aları ▁ile ▁birlikte ▁dön üştü ▁.\n",
            "▁ B u ▁birbirine ▁sık ı ca ▁bağlı ▁topluluk ▁kısa ▁süre ▁önce ▁bir ▁araya ▁geldi ▁ve ▁terk ▁edilmiş ▁bir ▁bin a ▁satın ▁aldı lar ▁, ▁yık ık ▁dök ük ▁ve ▁ip ot ekli ▁terk ▁edilmiş ▁bir ▁bin a ▁.\n",
            "▁ V e ▁dost ların ▁, ▁ail elerin ▁ve ▁gön ül lü lerin ▁yardım larıyla ▁beraber ▁, ▁kur ş un ▁geçir mez ▁cam ı ▁yık abil diler ▁, ▁yer leri ▁temiz ley eb il diler ▁ve ▁bur ayı ▁bir ▁toplum ▁mut f ağ ına ▁, ▁bir ▁kaf eye ▁, ▁v it r ine ▁çevir diler ▁.\n",
            "\n",
            "==> dev.en <==\n",
            "They decided to take a block-by-block-by-block strategy .\n",
            "So within the neighborhood of Brightmoor , you 'll find a 21-block microneighborhood called Brightmoor Farmway .\n",
            "Now , what was a notorious , unsafe , underserved community has transformed into a welcoming , beautiful , safe farmway , lush with parks and gardens and farms and greenhouses .\n",
            "This tight-knit community also came together recently , and they purchased an abandoned building , an abandoned building that was in disrepair and in foreclosure .\n",
            "And with the help of friends and families and volunteers , they were able to take down the bulletproof glass , they were able to clean up the grounds and they transformed that building into a community kitchen , into a cafe , into a storefront .\n",
            "\n",
            "==> dev.tr <==\n",
            "Onlar blok-blok işleme stratejisinde karar kıldılar .\n",
            "Dolayısıyla Brightmoor Mahallesi 'nde 21 bloktan oluşan Brightmoor Farmway adında mikro mahalleler görürsünüz .\n",
            "Şimdilerde , kötü şöhretli , güvenliksiz , yetersiz hizmet almış bu topluluk davetkar , güzel ve güvenli bir tarla yoluna , yemyeşil parkları , bahçeleri , tarlaları ve seraları ile birlikte dönüştü .\n",
            "Bu birbirine sıkıca bağlı topluluk kısa süre önce bir araya geldi ve terk edilmiş bir bina satın aldılar , yıkık dökük ve ipotekli terk edilmiş bir bina .\n",
            "Ve dostların , ailelerin ve gönüllülerin yardımlarıyla beraber , kurşun geçirmez camı yıkabildiler , yerleri temizleyebildiler ve burayı bir toplum mutfağına , bir kafeye , vitrine çevirdiler .\n",
            "==> test.bpe.en <==\n",
            "▁ M y ▁own ▁jour ney ▁to ▁work ▁with ▁these ▁children ▁started ▁as ▁a ▁te en ag er ▁.\n",
            "▁ I ▁was ▁ 15 ▁when ▁ I ▁was ▁g ang - ra ped ▁by ▁eight ▁men ▁.\n",
            "▁ I ▁don ▁' t ▁rem ember ▁the ▁ra pe ▁part ▁of ▁it ▁so ▁much ▁as ▁much ▁as ▁the ▁an ger ▁part ▁of ▁it ▁.\n",
            "▁ Y es ▁, ▁there ▁were ▁eight ▁men ▁who ▁def iled ▁me ▁, ▁ra ped ▁me ▁, ▁but ▁that ▁did n ▁' t ▁go ▁into ▁my ▁cons c ious ness ▁.\n",
            "▁ I ▁never ▁felt ▁like ▁a ▁vict im ▁, ▁then ▁or ▁now ▁.\n",
            "\n",
            "==> test.bpe.tr <==\n",
            "▁ B u ▁çocuk larla ▁çalışma ▁hik ay em ▁ben ▁genç ▁kız ken ▁başladı ▁.\n",
            "▁ 8 ▁erkek ▁tarafından ▁top lu ▁tec av üz e ▁uğr adı ğ ım da ▁ 15 ▁yaşında y d ım ▁.\n",
            "▁ T ec av üz ▁kısm ını ▁, ▁ö f ke ▁kısm ını ▁kadar ▁net ▁an ım say am ıyor um ▁.\n",
            "▁ E vet ▁, ▁ 8 ▁erkek ▁b eni ▁kir let ti ▁, ▁ır z ım a ▁geçti ▁, ▁ama ▁bu ▁bilin c ime ▁işlem edi ▁.\n",
            "▁ H iç ▁bir ▁zaman ▁, ▁ne ▁o ▁zaman ▁n ede ▁şim di ▁bir ▁kur ban ▁gibi ▁hiss et med im ▁.\n",
            "\n",
            "==> test.en <==\n",
            "My own journey to work with these children started as a teenager .\n",
            "I was 15 when I was gang-raped by eight men .\n",
            "I don 't remember the rape part of it so much as much as the anger part of it .\n",
            "Yes , there were eight men who defiled me , raped me , but that didn 't go into my consciousness .\n",
            "I never felt like a victim , then or now .\n",
            "\n",
            "==> test.tr <==\n",
            "Bu çocuklarla çalışma hikayem ben genç kızken başladı .\n",
            "8 erkek tarafından toplu tecavüze uğradığımda 15 yaşındaydım .\n",
            "Tecavüz kısmını , öfke kısmını kadar net anımsayamıyorum .\n",
            "Evet , 8 erkek beni kirletti , ırzıma geçti , ama bu bilincime işlemedi .\n",
            "Hiç bir zaman , ne o zaman nede şimdi bir kurban gibi hissetmedim .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "iBRMm4kMxZ8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1705637-3499-49c4-dda9-ce2efc744a4e"
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install .\n",
        "# Install Pytorch with GPU support v1.7.1.\n",
        "! pip install torch==1.8.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.5 MB/s eta 0:03:41tcmalloc: large alloc 1147494400 bytes == 0x561cb7326000 @  0x7f9d66b64615 0x561c7d6df02c 0x561c7d7bf17a 0x561c7d6e1e4d 0x561c7d7d3c0d 0x561c7d7560d8 0x561c7d750c35 0x561c7d6e373a 0x561c7d755f40 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d6e3b99 0x561c7d726e79 0x561c7d6e27b2 0x561c7d755e65 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d750c35 0x561c7d6e373a 0x561c7d751b0e 0x561c7d6e365a 0x561c7d751d67 0x561c7d750c35\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.3 MB/s eta 0:01:18tcmalloc: large alloc 1434370048 bytes == 0x561cfb97c000 @  0x7f9d66b64615 0x561c7d6df02c 0x561c7d7bf17a 0x561c7d6e1e4d 0x561c7d7d3c0d 0x561c7d7560d8 0x561c7d750c35 0x561c7d6e373a 0x561c7d755f40 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d7d4a56 0x561c7d751fb3 0x561c7d6e3b99 0x561c7d726e79 0x561c7d6e27b2 0x561c7d755e65 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d750c35 0x561c7d6e373a 0x561c7d751b0e 0x561c7d6e365a 0x561c7d751d67 0x561c7d750c35\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.4 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x561d51168000 @  0x7f9d66b64615 0x561c7d6df02c 0x561c7d7bf17a 0x561c7d6e1e4d 0x561c7d7d3c0d 0x561c7d7560d8 0x561c7d750c35 0x561c7d6e373a 0x561c7d751d67 0x561c7d750c35 0x561c7d6e373a 0x561c7d751d67 0x561c7d750c35 0x561c7d6e373a 0x561c7d751d67 0x561c7d750c35 0x561c7d6e373a 0x561c7d751d67 0x561c7d750c35 0x561c7d6e373a 0x561c7d751d67 0x561c7d6e365a 0x561c7d751d67 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d750c35 0x561c7d6e373a 0x561c7d75293b 0x561c7d750c35 0x561c7d6e3dd1\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 12 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 164 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.20.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.9.0 requires torch==1.8.0, but you have torch 1.7.1+cu110 which is incompatible.\n",
            "joeynmt 1.3 requires torch==1.8.0, but you have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchvision-0.8.2+cu110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwNhkXPXtFtx"
      },
      "source": [
        "# If continuing from previous run, load files from drive\n",
        "! cp \"$gdrive_path\"/dev.* .\n",
        "! cp \"$gdrive_path\"/train.* .\n",
        "! cp \"$gdrive_path\"/test.* ."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H-TyjtmXB1mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26aa4662-d9a7-4456-df44-cec50fc486b7"
      },
      "source": [
        "#Move everything important under joeynmt directory\n",
        "os.environ[\"data_path\"] = os.path.join(\"joeynmt\", \"data\", source_language + target_language)\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$src$tgt/vocab.txt  # Herman\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.bpe.en  dev.en  test.bpe.en  test.en  train.bpe.en\ttrain.en  vocab.txt\n",
            "dev.bpe.tr  dev.tr  test.bpe.tr  test.tr  train.bpe.tr\ttrain.tr\n",
            "Combined BPE Vocab\n",
            "▁spanish\n",
            "SMW\n",
            "KBI\n",
            "IS\n",
            "▁anton\n",
            "1784\n",
            "ò\n",
            "عسل\n",
            "مسكين\n",
            "T8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IlMitUHR8Qy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc67aaf-6eeb-4da6-a273-5f4ed5b585de"
      },
      "source": [
        "# If creating data for the first time, also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"  #See the contents of the drive directory"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.bpe.en  dev.tr\t test.bpe.tr  train.bpe.en  train.tr\n",
            "dev.bpe.tr  models\t test.en      train.bpe.tr\n",
            "dev.en\t    test.bpe.en  test.tr      train.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PIs1lY2hxMsl"
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"{gdrive_path}/models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 30                     # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: False               # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6ZBPFwT94WpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a80833-0648-4577-9a0e-e1251ea6df69"
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 12:41:07,414 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2021-07-28 12:41:07,439 - INFO - joeynmt.data - Loading training data...\n",
            "2021-07-28 12:41:15,383 - INFO - joeynmt.data - Building vocabulary...\n",
            "2021-07-28 12:41:17,439 - INFO - joeynmt.data - Loading dev data...\n",
            "2021-07-28 12:41:17,959 - INFO - joeynmt.data - Loading test data...\n",
            "2021-07-28 12:41:19,884 - INFO - joeynmt.data - Data loaded.\n",
            "2021-07-28 12:41:19,884 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2021-07-28 12:41:20,186 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2021-07-28 12:41:20.439783: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-28 12:41:22,372 - INFO - joeynmt.training - Total params: 13813760\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.name                           : entr_transformer\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.src                       : en\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.trg                       : tr\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.train                     : data/entr/train.bpe\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.dev                       : data/entr/dev.bpe\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.test                      : data/entr/test.bpe\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
            "2021-07-28 12:41:24,627 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/entr/vocab.txt\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/entr/vocab.txt\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
            "2021-07-28 12:41:24,628 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
            "2021-07-28 12:41:24,629 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2021-07-28 12:41:24,630 - INFO - joeynmt.helpers - cfg.training.epochs                : 30\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/entr_transformer\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.overwrite             : False\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
            "2021-07-28 12:41:24,631 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
            "2021-07-28 12:41:24,632 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 256\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
            "2021-07-28 12:41:24,633 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 256\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024\n",
            "2021-07-28 12:41:24,634 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
            "2021-07-28 12:41:24,635 - INFO - joeynmt.helpers - Data set sizes: \n",
            "\ttrain 296768,\n",
            "\tvalid 37437,\n",
            "\ttest 37439\n",
            "2021-07-28 12:41:24,635 - INFO - joeynmt.helpers - First training example:\n",
            "\t[SRC] ▁ T h ank ▁you ▁so ▁much ▁, ▁ C h ris ▁.\n",
            "\t[TRG] ▁ Ç ok ▁teş ek kür ▁eder im ▁ C h ris ▁.\n",
            "2021-07-28 12:41:24,635 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ▁ (5) ▁. (6) ▁, (7) ▁the (8) ▁' (9) ▁to\n",
            "2021-07-28 12:41:24,635 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ▁ (5) ▁. (6) ▁, (7) ▁the (8) ▁' (9) ▁to\n",
            "2021-07-28 12:41:24,635 - INFO - joeynmt.helpers - Number of Src words (types): 10756\n",
            "2021-07-28 12:41:24,636 - INFO - joeynmt.helpers - Number of Trg words (types): 10756\n",
            "2021-07-28 12:41:24,636 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=10756),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=10756))\n",
            "2021-07-28 12:41:24,651 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cuda\n",
            "\tn_gpu: 1\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 4096\n",
            "\ttotal batch size (w. parallel & accumulation): 4096\n",
            "2021-07-28 12:41:24,651 - INFO - joeynmt.training - EPOCH 1\n",
            "2021-07-28 12:41:59,555 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     5.799444, Tokens per Sec:     7181, Lr: 0.000300\n",
            "2021-07-28 12:42:33,760 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     5.377909, Tokens per Sec:     7330, Lr: 0.000300\n",
            "2021-07-28 12:43:08,126 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     5.341566, Tokens per Sec:     7383, Lr: 0.000300\n",
            "2021-07-28 12:43:42,387 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     5.182020, Tokens per Sec:     7349, Lr: 0.000300\n",
            "2021-07-28 12:44:16,931 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     5.123644, Tokens per Sec:     7375, Lr: 0.000300\n",
            "2021-07-28 12:44:51,135 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.864779, Tokens per Sec:     7200, Lr: 0.000300\n",
            "2021-07-28 12:45:25,116 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     5.106347, Tokens per Sec:     7338, Lr: 0.000300\n",
            "2021-07-28 12:45:59,157 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     4.892011, Tokens per Sec:     7160, Lr: 0.000300\n",
            "2021-07-28 12:46:33,553 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.624283, Tokens per Sec:     7370, Lr: 0.000300\n",
            "2021-07-28 12:47:07,511 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     4.166022, Tokens per Sec:     7184, Lr: 0.000300\n",
            "2021-07-28 13:52:54,154 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
            "2021-07-28 13:52:54,154 - INFO - joeynmt.training - Saving new checkpoint.\n",
            "2021-07-28 13:52:54,672 - INFO - joeynmt.training - Example #0\n",
            "2021-07-28 13:52:54,672 - INFO - joeynmt.training - \tSource:     ▁ T he y ▁decided ▁to ▁take ▁a ▁block - by - bl ock - by - bl ock ▁str ate gy ▁.\n",
            "2021-07-28 13:52:54,672 - INFO - joeynmt.training - \tReference:  ▁ O n lar ▁bl ok - b l ok ▁iş leme ▁str ate j isinde ▁karar ▁k ıldı lar ▁.\n",
            "2021-07-28 13:52:54,672 - INFO - joeynmt.training - \tHypothesis: ▁ B u ▁bir ▁şey ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁bir ▁şey ▁.\n",
            "2021-07-28 13:52:54,673 - INFO - joeynmt.training - Example #1\n",
            "2021-07-28 13:52:54,673 - INFO - joeynmt.training - \tSource:     ▁ S o ▁within ▁the ▁neighbor hood ▁of ▁ B right m oor ▁, ▁you ▁' ll ▁find ▁a ▁ 2 1 - bl ock ▁mic r one igh bor hood ▁called ▁ B right m oor ▁ F arm way ▁.\n",
            "2021-07-28 13:52:54,673 - INFO - joeynmt.training - \tReference:  ▁ D ol ay ısıyla ▁ B right mo or ▁ M ah all esi ▁' nde ▁ 2 1 ▁bl ok tan ▁oluşan ▁ B right mo or ▁ F ar m way ▁adında ▁mik ro ▁mahall eler ▁gör ür s ün üz ▁.\n",
            "2021-07-28 13:52:54,673 - INFO - joeynmt.training - \tHypothesis: ▁ B u ▁ A m erik ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁' ▁'\n",
            "2021-07-28 13:52:54,673 - INFO - joeynmt.training - Example #2\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tSource:     ▁ N ow ▁, ▁what ▁was ▁a ▁not or ious ▁, ▁uns af e ▁, ▁und ers erved ▁community ▁has ▁transform ed ▁into ▁a ▁wel com ing ▁, ▁beaut if ul ▁, ▁sa fe ▁farm way ▁, ▁l ush ▁with ▁par ks ▁and ▁gard ens ▁and ▁far ms ▁and ▁green h ous es ▁.\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tReference:  ▁ Ş im diler de ▁, ▁kötü ▁ş ö h ret li ▁, ▁güvenlik siz ▁, ▁yet ersiz ▁hizmet ▁almış ▁bu ▁topluluk ▁dav et kar ▁, ▁güzel ▁ve ▁güven li ▁bir ▁tar la ▁yol una ▁, ▁yem y eşil ▁park ları ▁, ▁bahç eleri ▁, ▁tar l aları ▁ve ▁ser aları ▁ile ▁birlikte ▁dön üştü ▁.\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tHypothesis: ▁ B u ▁bir ▁şey ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁, ▁ B u ▁bir ▁şey ▁bir ▁şey ▁bir ▁şey ▁, ▁ B u ▁bir ▁şey ▁bir ▁şey ▁bir ▁şey ▁.\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - Example #3\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tSource:     ▁ T h is ▁t ight - kn it ▁community ▁also ▁came ▁together ▁recently ▁, ▁and ▁they ▁purchased ▁an ▁aband oned ▁building ▁, ▁an ▁aband oned ▁building ▁that ▁was ▁in ▁dis rep air ▁and ▁in ▁fore cl os ure ▁.\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tReference:  ▁ B u ▁birbirine ▁sık ı ca ▁bağlı ▁topluluk ▁kısa ▁süre ▁önce ▁bir ▁araya ▁geldi ▁ve ▁terk ▁edilmiş ▁bir ▁bin a ▁satın ▁aldı lar ▁, ▁yık ık ▁dök ük ▁ve ▁ip ot ekli ▁terk ▁edilmiş ▁bir ▁bin a ▁.\n",
            "2021-07-28 13:52:54,674 - INFO - joeynmt.training - \tHypothesis: ▁ B u ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁, ▁bu ▁bir ▁şey ▁.\n",
            "2021-07-28 13:52:54,675 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   2.36, loss: 4971087.0000, ppl:  85.6942, duration: 3947.1637s\n",
            "2021-07-28 13:53:29,330 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     4.554379, Tokens per Sec:     7277, Lr: 0.000300\n",
            "2021-07-28 13:54:03,665 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     4.641875, Tokens per Sec:     7207, Lr: 0.000300\n",
            "2021-07-28 13:54:38,414 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     4.574217, Tokens per Sec:     7391, Lr: 0.000300\n",
            "2021-07-28 13:55:12,617 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     4.474820, Tokens per Sec:     7263, Lr: 0.000300\n",
            "2021-07-28 13:55:46,924 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.894049, Tokens per Sec:     7263, Lr: 0.000300\n",
            "2021-07-28 13:56:21,160 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     4.520405, Tokens per Sec:     7338, Lr: 0.000300\n",
            "2021-07-28 13:56:55,679 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     4.407074, Tokens per Sec:     7296, Lr: 0.000300\n",
            "2021-07-28 13:57:30,252 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     4.304127, Tokens per Sec:     7381, Lr: 0.000300\n",
            "2021-07-28 13:58:04,468 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.582899, Tokens per Sec:     7350, Lr: 0.000300\n",
            "2021-07-28 13:58:38,920 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.998873, Tokens per Sec:     7335, Lr: 0.000300\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 48, in <module>\n",
            "    main()\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 35, in main\n",
            "    train(cfg_file=args.config_path, skip_test=args.skip_test)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 805, in train\n",
            "    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 475, in train_and_validate\n",
            "    valid_duration = self._validate(valid_data, epoch_no)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 563, in _validate\n",
            "    n_gpu=self.n_gpu\n",
            "  File \"/content/joeynmt/joeynmt/prediction.py\", line 125, in validate_on_data\n",
            "    n_best=n_best)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 444, in run_batch\n",
            "    encoder_hidden=encoder_hidden)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 39, in greedy\n",
            "    src_mask, max_output_length, model, encoder_output, encoder_hidden)\n",
            "  File \"/content/joeynmt/joeynmt/search.py\", line 158, in transformer_greedy\n",
            "    if (finished >= 1).sum() == batch_size:\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MBoDS09JM807"
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "! mkdir -p \"$gdrive_path/models/${src}${tgt}_transformer/\"\n",
        "! cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qNinL_DvYhI"
      },
      "source": [
        "# If continuing from previous work load models from google drive to notebook storage  \n",
        "! mkdir -p joeynmt/models/${src}${tgt}_transformer\n",
        "! cp -r \"$gdrive_path/models/${src}${tgt}_transformer\" joeynmt/models"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "n94wlrCjVc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af45ae97-0cc7-4b8c-8474-6a02108ffbba"
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 1000\tLoss: 4971087.00000\tPPL: 85.69424\tbleu: 2.36058\tLR: 0.00030000\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "66WhRE9lIhoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43184620-ba2f-499e-b9d9-9ff9f2059ea8"
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 3, in <module>\n",
            "    from joeynmt.training import train\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 21, in <module>\n",
            "    from torchtext.legacy.data import Dataset\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchtext/__init__.py\", line 6, in <module>\n",
            "    from . import experimental\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchtext/experimental/__init__.py\", line 2, in <module>\n",
            "    from . import transforms\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchtext/experimental/transforms.py\", line 4, in <module>\n",
            "    from torchtext._torchtext import RegexTokenizer as RegexTokenizerPybind\n",
            "ImportError: /usr/local/lib/python3.7/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}